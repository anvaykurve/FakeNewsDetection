1. Exploring Columns: Title, Text, and Label

Loading Data: Use pd.read_csv('filename.csv') to import the dataset into a DataFrame.

Inspecting Structure:

Use df.head() to view the first 5 rows and understand the column structure (e.g., verifying title, text, and label exist).

Use df.columns to list all column names and df.dtypes to verify data types (ensuring text columns are objects/strings).

Use df.shape to see the total number of rows (articles) and columns.

---------------------------------------------------------
2.  Checking Missing Values and Basic Statistics

Missing Values:
Run df.isna().sum() to identify null values in the text or title columns.

Handling Nulls: If a news article has no text, it cannot be classified. You can drop these rows using df.dropna() or fill them if appropriate.

Basic Statistics:

Use df.describe() to get summary statistics. While typically for numbers, on text columns, it shows unique counts and the most frequent entries (useful for spotting duplicate articles).

Duplicate Detection: Use df.duplicated().sum() to check for repeated articles, which can bias the model.

----------------------------------------------------------
3. Removing Unwanted Columns

Dropping Columns:

Identify columns irrelevant to classification (e.g., id, author, index).

Use df.drop(['column_name'], axis=1) to remove them.

Subsetting: Alternatively, select only the columns you need: df = df[['title', 'text', 'label']].copy().
------------------------------------------------------------------
